# -*- coding: utf-8 -*-
"""ML.Assignment1.Ellis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g7OB__89fcT6bfJs2S9ISpjWTVOrLiWX
"""

!pip install tensorflow

import tensorflow as tf

!pip install keras

import keras as keras

from tensorflow.keras.datasets import imdb
(train_data,train_labels),(test_data,test_labels)=imdb.load_data(num_words=10000)

train_data[0]

train_labels[0]

max([max(sequence)for sequence in train_data])

def vectorize_sequences(sequences, dimension=10000):
    results = np.zeros((len(sequences), dimension))
    for i, sequence in enumerate(sequences):
        results[i, sequence] = 1.  # set specific indices of results[i] to 1s
    return results

"""Using One Hidden Layer and Testing Accuracy and Validation"""

from tensorflow import keras
from tensorflow.keras import layers
model = keras.Sequential([
    layers.Dense(16,activation="relu"),
    layers.Dense(1, activation="sigmoid")
])

model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])

import numpy as np

x_train = vectorize_sequences(train_data)

x_test = vectorize_sequences(test_data)

y_train = np.asarray(train_labels).astype('float32')
y_test = np.asarray(test_labels).astype('float32')

x_val= x_train[:10000]
partial_x_train= x_train[10000:]
y_val= y_train[:10000]
partial_y_train= y_train[10000:]

model.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['acc'])

history= model.fit(partial_x_train,
                    partial_y_train,
                    epochs=10,
                    batch_size=512,
                    )

results=model.evaluate(x_test,y_test)

results

"""The training data has a 96% accuracy with the model. The test data has a 87% accuracy with the model, which is significantly lower. However, the change from a two layer model to a one layer model only has a change in accuracy of 1.1%.

Layers with Various Hidden Units
"""

modeL_32units = keras.Sequential([
    layers.Dense(32,activation="relu"),
    layers.Dense(1, activation="sigmoid")
])

modeL_32units.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history_32= modeL_32units.fit(partial_x_train,
                    partial_y_train,
                    epochs=10,
                    batch_size=512,
                    )

results_32units=modeL_32units.evaluate(x_test,y_test)

results_32units

model_64units = keras.Sequential([
    layers.Dense(64,activation="relu"),
    layers.Dense(1, activation="sigmoid")
])

model_64units.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history_64=model_64units.fit(partial_x_train,
                    partial_y_train,
                    epochs=10,
                    batch_size=512,
                    )

results_64= model_64units.evaluate(x_test,y_test)

results_64

mode_128units = keras.Sequential([
    layers.Dense(128,activation="relu"),
    layers.Dense(1, activation="sigmoid")
])

mode_128units.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history_128=mode_128units.fit(partial_x_train,
                    partial_y_train,
                    epochs=10,
                    batch_size=512,
                    )

results_128= mode_128units.evaluate(x_test,y_test)

results_128

"""Changing the units does change the accuracy but not by drastic amounts.

Using MSE Loss Function
"""

model.compile(optimizer='rmsprop',
              loss='mse',
              metrics=['mae'])

history_mse= model.fit(partial_x_train,
                    partial_y_train,
                    epochs=10,
                    batch_size=512,
                    )

"""Changing Activation to 'tanh'"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
model_act = keras.Sequential([
    layers.Dense(16,activation="tanh"),
    layers.Dense(1, activation="sigmoid")
])

model_act.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])

import numpy as np

x_train = tf.keras.preprocessing.text.vectorize_sequences(train_data)
x_test = tf.keras.preprocessing.text.vectorize_sequences(test_data)
y_train = np.asarray(train_labels).astype('float32')
y_test = np.asarray(test_labels).astype('float32')

x_val= x_train[:10000]
partial_x_train= x_train[10000:]
y_val= y_train[:10000]
partial_y_train= y_train[10000:]

history= model_act.fit(partial_x_train,
                    partial_y_train,
                    epochs=10,
                    batch_size=512,
                    )

Creating Better Validation

from tensorflow import keras
from tensorflow.keras import layers
model_better = keras.Sequential([
    layers.Dense(16,activation="relu"),
    layers.Dense(16,activation="relu"),
    layers.Dense(16,activation="relu"),
    layers.Dense(16,activation="relu"),
    layers.Dense(16,activation="relu"),
    layers.Dense(16,activation="relu"),
    layers.Dense(16,activation="relu"),
    layers.Dense(1, activation="sigmoid")
])

model_better.compile(optimizer='rmsprop',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history_better= model_better.fit(partial_x_train,
                    partial_y_train,
                    epochs=10,
                    batch_size=512,
                    )

results_better= model_better.evaluate(x_test,y_test)

results_better